import torch
import torch.nn as nn
import torchvision
from torch.utils.data import DataLoader, TensorDataset
import numpy as np

import os
os.chdir("/local-scratch/GlucoseProject/mobicom23_mobispectral/regression")
import sys
sys.path.append(os.getcwd())

def Conv3x3BNReLU(in_channels, out_channels):
    """
    Creates a convolutional block with a 3x3 convolution, batch normalization,
    and ReLU6 activation.
    """
    return nn.Sequential(
        nn.Conv2d(in_channels=in_channels, out_channels=out_channels,
                  kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(out_channels),
        nn.ReLU6(inplace=True)
    )

class VGG(nn.Module):
    def __init__(self, block_nums, num_classes=1, input_channels=3, input_size=(224,224)):
        """
        Parameters:
            block_nums (list): Number of convolutional blocks in each stage.
            num_classes (int): Number of output classes.
            input_channels (int): Number of channels in the input data.
            input_size (tuple): The spatial dimensions (height, width) of your input.
                                For example, (64, 64) when each sample is (50, 64, 64)
                                would be used with input_channels=50.
        """
        super(VGG, self).__init__()

        self.stage1 = self._make_layers(in_channels=input_channels, out_channels=64, block_num=block_nums[0])
        self.stage2 = self._make_layers(in_channels=64, out_channels=128, block_num=block_nums[1])
        self.stage3 = self._make_layers(in_channels=128, out_channels=256, block_num=block_nums[2])
        self.stage4 = self._make_layers(in_channels=256, out_channels=512, block_num=block_nums[3])
        self.stage5 = self._make_layers(in_channels=512, out_channels=512, block_num=block_nums[4])
        
        # Calculate the spatial size after 5 stages of pooling (each halves the dimensions).
        factor = 2 ** 5
        out_height = input_size[0] // factor
        out_width = input_size[1] // factor
        in_features = 512 * out_height * out_width

        self.classifier = nn.Sequential(
            nn.Linear(in_features=in_features, out_features=4096),
            nn.Dropout(p=0.2),
            nn.Linear(in_features=4096, out_features=4096),
            nn.Dropout(p=0.2),
            nn.Linear(in_features=4096, out_features=num_classes)
        )

        self._init_params()

    def _make_layers(self, in_channels, out_channels, block_num):
        layers = [Conv3x3BNReLU(in_channels, out_channels)]
        for _ in range(1, block_num):
            layers.append(Conv3x3BNReLU(out_channels, out_channels))
        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
        return nn.Sequential(*layers)

    def _init_params(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        if not torch.is_tensor(x):
            x = torch.tensor(x, dtype=torch.float32)

        x = self.stage1(x)
        x = self.stage2(x)
        x = self.stage3(x)
        x = self.stage4(x)
        x = self.stage5(x)
        # Flatten the final conv output:
        x = x.view(x.size(0), -1)
        out = self.classifier(x)
        return out

    def predict(self, x):
        """
        Performs prediction using the model.
        
        Parameters:
            x: Input data for prediction.
            
        Returns:
            torch.Tensor: The predictions generated by the model.
        """
        # Get the device that the model is on
        device = next(self.parameters()).device
        
        # Convert input to tensor if it's not already
        if not torch.is_tensor(x):
            x = torch.tensor(x, dtype=torch.float32)
        
        # Move input to the same device as the model
        x = x.to(device)
        
        # Set model to evaluation mode
        self.eval()
        
        # Perform prediction
        with torch.no_grad():
            output = self.forward(x)
        
        # Return predictions (move back to CPU for easier handling)
        return output.cpu()

def VGG16(input_channels=3, input_size=(224,224)):
    """
    Creates a VGG16 model with customizable input channels and input image size.
    
    Parameters:
        input_channels (int): The number of input channels.
        input_size (tuple): The spatial dimensions (height, width) of the input.
    """
    block_nums = [2, 2, 3, 3, 3]
    return VGG(block_nums, num_classes=1, input_channels=input_channels, input_size=input_size)

def VGG19(input_channels=3, input_size=(224,224)):
    """
    Creates a VGG19 model with customizable input channels and input image size.
    
    Parameters:
        input_channels (int): The number of input channels.
        input_size (tuple): The spatial dimensions (height, width) of the input.
    """
    block_nums = [2, 2, 4, 4, 4]
    return VGG(block_nums, num_classes=1, input_channels=input_channels, input_size=input_size)

def train(model, x_train, y_train, x_val=None, y_val=None,
          epochs=200, lr=1e-6, batch_size=32, device=None, patience=10):
    """
    Trains the VGG model using mean squared error loss for regression tasks with early stopping.
    
    Parameters:
        model (nn.Module): The VGG model to train.
        x_train (np.array or torch.Tensor): Training input data.
        y_train (np.array or torch.Tensor): Training target data.
        x_val (np.array or torch.Tensor, optional): Validation input data.
        y_val (np.array or torch.Tensor, optional): Validation target data.
        epochs (int): Number of epochs for training.
        lr (float): Learning rate.
        batch_size (int): Batch size for the DataLoader.
        device (torch.device, optional): The device on which to run training.
        patience (int): Number of consecutive epochs without improvement before stopping.
        
    Returns:
        nn.Module: The trained model loaded with the best weights (lowest validation loss).
    """
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    # Convert inputs to torch.Tensor if needed
    if not torch.is_tensor(x_train):
        x_train = torch.tensor(x_train, dtype=torch.float32)
    if not torch.is_tensor(y_train):
        y_train = torch.tensor(y_train, dtype=torch.float32)

    train_dataset = TensorDataset(x_train, y_train)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    val_loader = None
    if x_val is not None and y_val is not None:
        if not torch.is_tensor(x_val):
            x_val = torch.tensor(x_val, dtype=torch.float32)
        if not torch.is_tensor(y_val):
            y_val = torch.tensor(y_val, dtype=torch.float32)
        val_dataset = TensorDataset(x_val, y_val)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    criterion = nn.MSELoss()

    best_loss = float('inf')
    epochs_without_improvement = 0
    best_model_state = None

    for epoch in range(epochs):
        model.train()
        train_loss = 0.0

        for batch_x, batch_y in train_loader:
            batch_x, batch_y = batch_x.to(device), batch_y.to(device)
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        avg_train_loss = train_loss / len(train_loader)

        if val_loader is not None:
            model.eval()
            val_loss = 0.0
            with torch.no_grad():
                for val_x, val_y in val_loader:
                    val_x, val_y = val_x.to(device), val_y.to(device)
                    outputs = model(val_x)
                    loss = criterion(outputs, val_y)
                    val_loss += loss.item()
            avg_val_loss = val_loss / len(val_loader)
            print(f"Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.4f} - Val Loss: {avg_val_loss:.4f}")

            # Check for improvement in the validation loss.
            if avg_val_loss < best_loss:
                best_loss = avg_val_loss
                best_model_state = model.state_dict()
                epochs_without_improvement = 0
                # Optionally, save the best model to disk:
                torch.save(best_model_state, "./Models/VGG_best_model.pth")
            else:
                epochs_without_improvement += 1
                if epochs_without_improvement >= patience:
                    print(f"Early stopping triggered. No improvement for {patience} consecutive epochs.")
                    # Load the best model state before returning.
                    if best_model_state is not None:
                        model.load_state_dict(best_model_state)
                    break
        else:
            print(f"Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.4f}")

    return model

def predict(model, x, device=None, batch_size=32):
    """
    Performs prediction using the trained model.
    
    Parameters:
        model (nn.Module): The trained VGG model.
        x (np.array or torch.Tensor): Input data for prediction.
        device (torch.device, optional): The device on which to perform prediction.
        batch_size (int): Batch size for prediction.
        
    Returns:
        torch.Tensor: The predictions generated by the model.
    """
    if device is None:
        # Use the device that the model is currently on
        device = next(model.parameters()).device
    
    model.to(device)
    model.eval()

    if not torch.is_tensor(x):
        x = torch.tensor(x, dtype=torch.float32).to(device)

    # Wrap input in a TensorDataset to ease batching
    dataset = TensorDataset(x)
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

    predictions = []
    with torch.no_grad():
        for batch in loader:
            inputs = batch[0].to(device)  # batch is a tuple from TensorDataset
            outputs = model(inputs)
            predictions.append(outputs.cpu())
    predictions = torch.cat(predictions, dim=0)
    return predictions

if __name__ == '__main__':
    # Demonstration of forward pass
    model = VGG16(input_channels=50, input_size=(64, 64))
    print("Model architecture:")
    print(model)

    # input_tensor = torch.randn(1, 50, 64, 64)
    # output = model(input_tensor)
    # print("Output shape from forward pass:", output.shape)

    # Synthetic training example
    # Here, we create random data for demonstration purposes.
    x_train = torch.randn(100, 50, 64, 64)
    y_train = torch.randn(100, 1)
    x_val = torch.randn(20, 50, 64, 64)
    y_val = torch.randn(20, 1)

    print("\nStarting training on synthetic data...")
    trained_model = train(model, x_train, y_train, x_val, y_val,
                                epochs=5, lr=1e-3, batch_size=8)

    # Demonstration of prediction
    predictions = predict(trained_model, x_val, batch_size=8)
    
    # # test_data is dictionary of image and label
    # # test_data['sig'] is numpy array of shape (50, 64, 64)
    # # test_data['label'] is numpy array of shape (1,)
    # # Below is the synthetic data of test_data
    # test_data = {'sig': x_val, 'label': y_val}

    # evaluate_image_CEG(test_data, model=None, path=None, scaler_X=None, scaler_y=None, show=True, save_path=None)
    print("Predictions shape:", predictions.shape)